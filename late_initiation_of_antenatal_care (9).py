# -*- coding: utf-8 -*-
"""late initiation of antenatal care.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZgArXe8W-Cvkr1dctEQdPgVBTV2RyvWc
"""

# Step 0: Import required libraries
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Step 1: Load the dataset
file_path = "/content/East_African_countries_data.csv"  # Change this path if needed
df = pd.read_csv(file_path)

# Step 2: Encode the target variable ('anc_timing': early=0, late=1)
df['anc_timing'] = df['anc_timing'].map({'early': 0, 'late': 1})

# Step 3: List of categorical columns to encode
categorical_columns = [
    'country', 'residence', 'education_1', 'birth_order',
    'wealth', 'household_size_g', 'household_sex', 'age_group_new_cat'
]

# Step 4: Encode categorical variables using LabelEncoder
label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Save the encoder for future use if needed

# Step 5: Display the first few rows and check for missing values
print("First 5 rows of the processed dataset:")
print(df.head())

print("\nMissing values in each column:")
print(df.isnull().sum())

"""# Exploratory Data Analysis (EDA)"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set plot style
sns.set(style="whitegrid")

# 1. Class balance for anc_timing
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='anc_timing')
plt.title('ANC Timing Distribution (0 = Early, 1 = Late)')
plt.xlabel('ANC Timing')
plt.ylabel('Count')
plt.show()

# 2. Distribution of key features by ANC timing
features_to_plot = ['residence', 'education_1', 'birth_order', 'wealth', 'age_group_new_cat']

for feature in features_to_plot:
    plt.figure(figsize=(6, 4))
    sns.countplot(data=df, x=feature, hue='anc_timing')
    plt.title(f'{feature} vs ANC Timing')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.legend(title='ANC Timing')
    plt.show()

# 3. Correlation heatmap
plt.figure(figsize=(10, 8))
corr = df.drop(columns=['psu', 'new_psu', 'DHSCLUST', 'newcaseid_1']).corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title("Feature Correlation Heatmap")
plt.show()

# 1. ANC Timing by Country
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='country', hue='anc_timing')
plt.title('ANC Timing by Country')
plt.xlabel('Country (Encoded)')
plt.ylabel('Count')
plt.legend(title='ANC Timing')
plt.show()

# 2. ANC Timing by Education Level
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='education_1', hue='anc_timing')
plt.title('ANC Timing by Education Level')
plt.xlabel('Education Level (Encoded)')
plt.ylabel('Count')
plt.legend(title='ANC Timing')
plt.show()

# 3. ANC Timing by Birth Order
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='birth_order', hue='anc_timing')
plt.title('ANC Timing by Birth Order')
plt.xlabel('Birth Order (Encoded)')
plt.ylabel('Count')
plt.legend(title='ANC Timing')
plt.show()

# 4. ANC Timing by Residence
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='residence', hue='anc_timing')
plt.title('ANC Timing by Residence (Urban=0, Rural=1)')
plt.xlabel('Residence')
plt.ylabel('Count')
plt.legend(title='ANC Timing')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Select features and target
features = [
    'country', 'residence', 'education_1', 'birth_order', 'wealth',
    'household_size_g', 'household_sex', 'age_group_new_cat'
]
target = 'anc_timing'

X = df[features]
y = df[target]

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit logistic regression model
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)

# Predict on test set
y_pred = logreg.predict(X_test)

# Evaluate the model
print("Accuracy Score:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

# Initialize and train the model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict
y_pred_rf = rf_model.predict(X_test)

# Evaluate
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_rf))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_rf))

rf_balanced = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
rf_balanced.fit(X_train, y_train)
y_pred_bal = rf_balanced.predict(X_test)

print("Balanced RF Accuracy:", accuracy_score(y_test, y_pred_bal))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_bal))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_bal))

import pandas as pd

# Feature importance
importances = rf_balanced.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

print(feature_importance_df)

# Visualize
plt.figure(figsize=(8, 5))
sns.barplot(data=feature_importance_df, x='Importance', y='Feature')
plt.title('Feature Importance - Random Forest')
plt.show()

